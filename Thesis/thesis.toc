\thispagestyle {empty}
\contentsline {section}{\numberline {0.1}Project Proposal for Bachelor Thesis}{ii}{section.0.1}
\contentsline {subsection}{\numberline {0.1.1}Motivation}{ii}{subsection.0.1.1}
\contentsline {subsection}{\numberline {0.1.2}Background}{ii}{subsection.0.1.2}
\contentsline {subsection}{\numberline {0.1.3}Scope of the Project}{iii}{subsection.0.1.3}
\contentsline {chapter}{List of figures}{ix}{chapter*.4}
\contentsline {chapter}{List of tables}{xi}{chapter*.5}
\contentsline {chapter}{\numberline {1}Background}{1}{chapter.1}
\contentsline {section}{\numberline {1.1}Bayesian Optimization in high dimensions}{1}{section.1.1}
\contentsline {section}{\numberline {1.2}Gaussian Processes}{2}{section.1.2}
\contentsline {subsection}{\numberline {1.2.1}Derivation of the Gaussian Process Formula}{3}{subsection.1.2.1}
\contentsline {section}{\numberline {1.3}Acquisition Functions}{4}{section.1.3}
\contentsline {subsection}{\numberline {1.3.1}Upper Confident Bound (UCB)}{4}{subsection.1.3.1}
\contentsline {subsection}{\numberline {1.3.2}Probability of Improvement (PI)}{4}{subsection.1.3.2}
\contentsline {subsection}{\numberline {1.3.3}Expected Improvement (EI)}{4}{subsection.1.3.3}
\contentsline {section}{\numberline {1.4}Resources}{5}{section.1.4}
\contentsline {chapter}{\numberline {2}Related Work}{7}{chapter.2}
\contentsline {section}{\numberline {2.1}Projection matrix based algorithms}{7}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}Active learning of linear subspace}{7}{subsection.2.1.1}
\contentsline {subsection}{\numberline {2.1.2}High dimensional Gaussian bandits}{9}{subsection.2.1.2}
\contentsline {subsection}{\numberline {2.1.3}Random embeddings (REMBO)}{9}{subsection.2.1.3}
\contentsline {subsection}{\numberline {2.1.4}Applications to high-dimensional uncertainty propogation}{11}{subsection.2.1.4}
\contentsline {paragraph}{I now proceed with a more detailed description of the algorithm.}{12}{section*.8}
\contentsline {subsubsection}{Kernel used}{12}{section*.9}
\contentsline {subsubsection}{Step 1.: Determine the active projection matrix W}{13}{section*.10}
\contentsline {subsubsection}{Step 2.: Optimizing over GP noise variance and the kernel hyperparameters}{14}{section*.11}
\contentsline {subsubsection}{Additional details}{14}{section*.12}
\contentsline {subsubsection}{Identification of active subspace dimension }{14}{section*.13}
\contentsline {section}{\numberline {2.2}Algorithms that exploit additive substructures}{15}{section.2.2}
\contentsline {subsection}{\numberline {2.2.1}Independent additive structures within the target function}{15}{subsection.2.2.1}
\contentsline {section}{\numberline {2.3}Additional approaches}{15}{section.2.3}
\contentsline {subsection}{\numberline {2.3.1}Elastic Gaussian Processes}{15}{subsection.2.3.1}
\contentsline {subsection}{\numberline {2.3.2}Bayesian Optimization using Dropout}{15}{subsection.2.3.2}
\contentsline {chapter}{\numberline {3}Fields of Improvement}{17}{chapter.3}
\contentsline {section}{\numberline {3.1}Shortcomings of current methods}{17}{section.3.1}
\contentsline {paragraph}{REMBO}{17}{section*.14}
\contentsline {paragraph}{Active subgradients}{18}{section*.15}
\contentsline {paragraph}{Tripathy's method}{18}{section*.16}
\contentsline {section}{\numberline {3.2}Method of measuring improvements}{19}{section.3.2}
\contentsline {subsection}{\numberline {3.2.1}Synthetic Datasets}{20}{subsection.3.2.1}
\contentsline {paragraph}{5 dimensional function with 2 dimensional linear embedding}{20}{section*.17}
\contentsline {paragraph}{2D to 1D}{20}{section*.18}
\contentsline {paragraph}{5D to 2D}{20}{section*.19}
\contentsline {paragraph}{5D to 2D}{20}{section*.20}
\contentsline {subsection}{\numberline {3.2.2}Real Datasets}{20}{subsection.3.2.2}
\contentsline {paragraph}{SwissFEL dataset}{20}{section*.21}
\contentsline {chapter}{\numberline {4}Model Design and Extensions to the state of the art}{21}{chapter.4}
\contentsline {section}{\numberline {4.1}The BORING Algorithm}{21}{section.4.1}
\contentsline {subsection}{\numberline {4.1.1}Algorithm Description}{22}{subsection.4.1.1}
\contentsline {subsubsection}{Overview}{22}{section*.22}
\contentsline {subsubsection}{Finding a basis for the passive subspace (a subspace orthogonal to the active subspace)}{23}{section*.23}
\contentsline {subsubsection}{Additive UCB acquisition function}{25}{section*.24}
\contentsline {subsubsection}{How does our algorithm address the shortcomings from chapter 3?}{25}{section*.25}
\contentsline {chapter}{\numberline {5}Evaluation}{27}{chapter.5}
\contentsline {section}{\numberline {5.1}Evaluation Settings}{27}{section.5.1}
\contentsline {section}{\numberline {5.2}Quantitative evaluation}{27}{section.5.2}
\contentsline {section}{\numberline {5.3}Qualitative evaluation}{29}{section.5.3}
\contentsline {subsection}{\numberline {5.3.1}Feature selection}{29}{subsection.5.3.1}
\contentsline {subsection}{\numberline {5.3.2}Subspace identification}{31}{subsection.5.3.2}
\contentsline {chapter}{\numberline {6}Conclusion}{37}{chapter.6}
\contentsline {section}{\numberline {6.1}Main Contributions}{37}{section.6.1}
\contentsline {section}{\numberline {6.2}Conclusion}{38}{section.6.2}
\contentsline {chapter}{References}{39}{chapter*.34}
\contentsline {chapter}{Appendix \numberline {A}}{41}{Appendix.a.A}
\contentsline {section}{\numberline {A.1}Benchmarking functions}{41}{section.a.A.1}
