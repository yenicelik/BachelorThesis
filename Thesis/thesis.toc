\thispagestyle {empty}
\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}
\contentsline {subsection}{\numberline {1.0.1}Motivation}{1}{subsection.1.0.1}
\contentsline {subsection}{\numberline {1.0.2}Background}{1}{subsection.1.0.2}
\contentsline {subsection}{\numberline {1.0.3}Scope of the Project}{2}{subsection.1.0.3}
\contentsline {chapter}{\numberline {2}Background}{5}{chapter.2}
\contentsline {section}{\numberline {2.1}Bayesian Optimization in high dimensions}{5}{section.2.1}
\contentsline {section}{\numberline {2.2}Gaussian Processes}{6}{section.2.2}
\contentsline {subsection}{\numberline {2.2.1}Derivation of the Gaussian Process Formula}{6}{subsection.2.2.1}
\contentsline {section}{\numberline {2.3}Acquisition Functions}{8}{section.2.3}
\contentsline {subsection}{\numberline {2.3.1}Upper Confident Bound (UCB)}{8}{subsection.2.3.1}
\contentsline {subsection}{\numberline {2.3.2}Probability of Improvement (PI)}{8}{subsection.2.3.2}
\contentsline {subsection}{\numberline {2.3.3}Expected Improvement (EI)}{8}{subsection.2.3.3}
\contentsline {section}{\numberline {2.4}Resources}{9}{section.2.4}
\contentsline {chapter}{\numberline {3}Related Work}{11}{chapter.3}
\contentsline {section}{\numberline {3.1}Projection matrix-based algorithms}{11}{section.3.1}
\contentsline {subsection}{\numberline {3.1.1}Active learning of linear subspaces}{12}{subsection.3.1.1}
\contentsline {subsection}{\numberline {3.1.2}Random embeddings (REMBO)}{13}{subsection.3.1.2}
\contentsline {subsection}{\numberline {3.1.3}GPs with builtin dimensionality reduction}{15}{subsection.3.1.3}
\contentsline {paragraph}{Formal description of the algorithm.}{16}{section*.6}
\contentsline {subsubsection}{The Matern32 Kernel}{16}{section*.7}
\contentsline {subsection}{\numberline {3.1.4}Overview of the algorithm}{17}{subsection.3.1.4}
\contentsline {subsubsection}{Step 1.: Determine the active projection matrix W}{17}{section*.8}
\contentsline {subsubsection}{Step 2.: Optimizing over GP noise variance and the kernel hyperparameters}{18}{section*.9}
\contentsline {subsubsection}{Additional details}{18}{section*.10}
\contentsline {subsubsection}{Identification of active subspace dimension }{19}{section*.11}
\contentsline {section}{\numberline {3.2}Algorithms that exploit additive substructures}{19}{section.3.2}
\contentsline {subsection}{\numberline {3.2.1}Independent additive structures within the target function}{19}{subsection.3.2.1}
\contentsline {section}{\numberline {3.3}Additional approaches}{19}{section.3.3}
\contentsline {subsection}{\numberline {3.3.1}Elastic Gaussian Processes}{19}{subsection.3.3.1}
\contentsline {subsection}{\numberline {3.3.2}High dimensional Gaussian bandits}{20}{subsection.3.3.2}
\contentsline {subsection}{\numberline {3.3.3}Bayesian Optimization using Dropout}{20}{subsection.3.3.3}
\contentsline {chapter}{\numberline {4}Analysis of the current state of the art}{21}{chapter.4}
\contentsline {section}{\numberline {4.1}Shortcomings of current methods}{21}{section.4.1}
\contentsline {paragraph}{REMBO}{21}{section*.12}
\contentsline {paragraph}{Active subgradients}{22}{section*.13}
\contentsline {paragraph}{Bilinois et al.}{22}{section*.14}
\contentsline {section}{\numberline {4.2}Evaluation methods}{23}{section.4.2}
\contentsline {subsection}{\numberline {4.2.1}Synthetic Datasets}{24}{subsection.4.2.1}
\contentsline {paragraph}{5 dimensional function with 2 dimensional linear embedding}{24}{section*.15}
\contentsline {paragraph}{2D to 1D}{24}{section*.16}
\contentsline {paragraph}{3D to 2D}{24}{section*.17}
\contentsline {paragraph}{5D to 2D}{24}{section*.18}
\contentsline {chapter}{\numberline {5}A New Model}{25}{chapter.5}
\contentsline {section}{\numberline {5.1}The BORING Algorithm}{25}{section.5.1}
\contentsline {subsection}{\numberline {5.1.1}Algorithm Description}{26}{subsection.5.1.1}
\contentsline {subsubsection}{Overview}{26}{section*.19}
\contentsline {subsubsection}{Finding a basis for the passive subspace (a subspace orthogonal to the active subspace)}{27}{section*.20}
\contentsline {subsubsection}{Additive UCB acquisition function}{29}{section*.21}
\contentsline {subsubsection}{How does our algorithm address the shortcomings from chapter 3?}{29}{section*.22}
\contentsline {chapter}{\numberline {6}Evaluation}{31}{chapter.6}
\contentsline {section}{\numberline {6.1}Evaluation Settings}{31}{section.6.1}
\contentsline {section}{\numberline {6.2}Quantitative evaluation}{31}{section.6.2}
\contentsline {subsection}{\numberline {6.2.1}Parabola}{32}{subsection.6.2.1}
\contentsline {paragraph}{Assume $\mathaccentV {hat}05E{W} = W_{\text {true}}$}{32}{section*.23}
\contentsline {paragraph}{Assume $\mathaccentV {hat}05E{W} \not =W_{\text {true}}$}{33}{section*.25}
\contentsline {subsection}{\numberline {6.2.2}Camelback embedded in 3D}{34}{subsection.6.2.2}
\contentsline {paragraph}{Assume $\mathaccentV {hat}05E{W} = W_{\text {true}}$}{34}{section*.27}
\contentsline {paragraph}{Assume $\mathaccentV {hat}05E{W} \not =W_{\text {true}}$}{34}{section*.29}
\contentsline {subsection}{\numberline {6.2.3}Camelback embedded in 5D}{35}{subsection.6.2.3}
\contentsline {paragraph}{Assume $\mathaccentV {hat}05E{W} = W_{\text {true}}$}{35}{section*.31}
\contentsline {paragraph}{Assume $\mathaccentV {hat}05E{W} \not =W_{\text {true}}$}{36}{section*.33}
\contentsline {subsection}{\numberline {6.2.4}Log-Likelihood and Angle difference measures}{37}{subsection.6.2.4}
\contentsline {paragraph}{Parabola}{37}{section*.35}
\contentsline {paragraph}{Camelback}{38}{section*.37}
\contentsline {paragraph}{Sinusoidal}{40}{section*.40}
\contentsline {section}{\numberline {6.3}REMBO}{41}{section.6.3}
\contentsline {paragraph}{Parabola}{42}{section*.42}
\contentsline {paragraph}{Camelback3D}{42}{section*.44}
\contentsline {paragraph}{Camelback5D}{43}{section*.46}
\contentsline {section}{\numberline {6.4}Qualitative evaluation}{43}{section.6.4}
\contentsline {subsection}{\numberline {6.4.1}Feature selection}{44}{subsection.6.4.1}
\contentsline {subsection}{\numberline {6.4.2}Subspace identification}{45}{subsection.6.4.2}
\contentsline {chapter}{\numberline {7}Conclusion}{49}{chapter.7}
\contentsline {section}{\numberline {7.1}Main Contributions}{49}{section.7.1}
\contentsline {section}{\numberline {7.2}Future work}{49}{section.7.2}
\contentsline {chapter}{References}{51}{chapter*.53}
\contentsline {chapter}{Appendix \numberline {A}Appendix A}{55}{Appendix.a.A}
\contentsline {section}{\numberline {A.1}Benchmarking functions}{55}{section.a.A.1}
\contentsline {section}{\numberline {A.2}The log-likelihood function as a function of $\tau $}{56}{section.a.A.2}
