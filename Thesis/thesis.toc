\thispagestyle {empty}
\contentsline {section}{\numberline {0.1}Project Proposal for Bachelor Thesis}{ii}{section.0.1}
\contentsline {subsection}{\numberline {0.1.1}Motivation}{ii}{subsection.0.1.1}
\contentsline {subsection}{\numberline {0.1.2}Background}{ii}{subsection.0.1.2}
\contentsline {subsection}{\numberline {0.1.3}Scope of the Project}{iii}{subsection.0.1.3}
\contentsline {chapter}{List of figures}{ix}{chapter*.4}
\contentsline {chapter}{List of tables}{xi}{chapter*.5}
\contentsline {chapter}{\numberline {1}Background}{1}{chapter.1}
\contentsline {section}{\numberline {1.1}Bayesian Optimization in high dimensions}{1}{section.1.1}
\contentsline {section}{\numberline {1.2}Gaussian Processes}{2}{section.1.2}
\contentsline {subsection}{\numberline {1.2.1}Derivation of the Gaussian Process Formula}{3}{subsection.1.2.1}
\contentsline {section}{\numberline {1.3}Acquisition Functions}{4}{section.1.3}
\contentsline {subsection}{\numberline {1.3.1}Upper Confident Bound (UCB)}{4}{subsection.1.3.1}
\contentsline {subsection}{\numberline {1.3.2}Probability of Improvement (PI)}{4}{subsection.1.3.2}
\contentsline {subsection}{\numberline {1.3.3}Expected Improvement (EI)}{4}{subsection.1.3.3}
\contentsline {section}{\numberline {1.4}Resources}{5}{section.1.4}
\contentsline {chapter}{\numberline {2}Related Work}{7}{chapter.2}
\contentsline {section}{\numberline {2.1}Projection matrix based algorithms}{7}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}Active learning of linear subspace}{7}{subsection.2.1.1}
\contentsline {subsection}{\numberline {2.1.2}High dimensional Gaussian bandits}{8}{subsection.2.1.2}
\contentsline {subsection}{\numberline {2.1.3}Random embeddings (REMBO)}{9}{subsection.2.1.3}
\contentsline {subsection}{\numberline {2.1.4}Applications to high-dimensional uncertainty propogation}{9}{subsection.2.1.4}
\contentsline {subsubsection}{Optimize $W \in V_d(\mathbb {R}^D)$ and keep $\phi $ and $s_n^2$ fixed}{10}{section*.6}
\contentsline {subsubsection}{Identification of active subspace dimension }{12}{section*.7}
\contentsline {section}{\numberline {2.2}Algorithms that exploit additive substructures}{12}{section.2.2}
\contentsline {subsection}{\numberline {2.2.1}Independent additive structures within the target function}{12}{subsection.2.2.1}
\contentsline {section}{\numberline {2.3}Additional approaches}{12}{section.2.3}
\contentsline {subsection}{\numberline {2.3.1}Elastic Gaussian Processes}{12}{subsection.2.3.1}
\contentsline {subsection}{\numberline {2.3.2}Bayesian Optimization using Dropout}{12}{subsection.2.3.2}
\contentsline {chapter}{\numberline {3}Fields of Improvement}{15}{chapter.3}
\contentsline {section}{\numberline {3.1}Shortcomings of current methods}{15}{section.3.1}
\contentsline {paragraph}{REMBO}{15}{section*.8}
\contentsline {paragraph}{Active subgradients}{16}{section*.9}
\contentsline {paragraph}{Tripathy's method}{16}{section*.10}
\contentsline {section}{\numberline {3.2}Method of measuring improvements}{17}{section.3.2}
\contentsline {subsection}{\numberline {3.2.1}Synthetic Datasets}{17}{subsection.3.2.1}
\contentsline {paragraph}{5 dimensional function with 2 dimensional linear embedding}{17}{section*.11}
\contentsline {paragraph}{2D to 1D}{17}{section*.12}
\contentsline {paragraph}{5D to 2D}{17}{section*.13}
\contentsline {paragraph}{5D to 2D}{18}{section*.14}
\contentsline {subsection}{\numberline {3.2.2}Real Datasets}{18}{subsection.3.2.2}
\contentsline {paragraph}{SwissFEL dataset}{18}{section*.15}
\contentsline {chapter}{\numberline {4}Model Design and Extensions to the state of the art}{19}{chapter.4}
\contentsline {section}{\numberline {4.1}The BORING Algorithm}{19}{section.4.1}
\contentsline {subsection}{\numberline {4.1.1}Algorithm Description}{20}{subsection.4.1.1}
\contentsline {subsubsection}{General Idea of the algorithm}{20}{section*.16}
\contentsline {subsubsection}{Finding a basis for the passive subspace (a subspace orthogonal to the active subspace)}{21}{section*.17}
\contentsline {subsubsection}{Additive UCB acquisition function}{23}{section*.18}
\contentsline {section}{\numberline {4.2}Additive Stiefel projections - Our proposed improvement to existing methods}{24}{section.4.2}
\contentsline {subsection}{\numberline {4.2.1}What is it better than actively finding substructures}{24}{subsection.4.2.1}
\contentsline {subsubsection}{How does our algorithm address the shortcomings from chapter 3?}{25}{section*.19}
\contentsline {chapter}{\numberline {5}Evaluation}{27}{chapter.5}
\contentsline {section}{\numberline {5.1}Evaluation Settings}{27}{section.5.1}
\contentsline {section}{\numberline {5.2}Quantitative evaluation}{27}{section.5.2}
\contentsline {section}{\numberline {5.3}Qualitative evaluation}{28}{section.5.3}
\contentsline {subsection}{\numberline {5.3.1}Finding a matrix when we apply a polynomial kernel onto the input first}{28}{subsection.5.3.1}
\contentsline {subsection}{\numberline {5.3.2}Subspace identification}{28}{subsection.5.3.2}
\contentsline {chapter}{References}{31}{chapter*.24}
\contentsline {chapter}{Appendix \numberline {A}}{33}{Appendix.a.A}
\contentsline {section}{\numberline {A.1}Benchmarking functions}{33}{section.a.A.1}
