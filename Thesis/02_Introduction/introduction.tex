%!TEX root = ../thesis.tex
%*******************************************************************************
%*********************************** First Chapter *****************************
%*******************************************************************************

\chapter{Background}  %Title of the First Chapter

\ifpdf
    \graphicspath{{Chapter1/Figs/Raster/}{Chapter1/Figs/PDF/}{Chapter1/Figs/}}
\else
    \graphicspath{{Chapter1/Figs/Vector/}{Chapter1/Figs/}}
\fi


%********************************** %First Section  **************************************
\section{Bayesian Optimization in high dimensions} %Section - 1.1 

Many of today's problems can be boiled down to some flavor of black box optimization. 
Such problems include neural architecture search, hyper-parameter search for neural networks, parameter optimization for electron accelerators, or drone parameter optimization using safety constraints (CITE Johannes). \\

Bayesian optimization methods are a class of sequential black-box optimization methods, where we learn a surrogate function surface using a Gaussian prior, and a Gaussian likelihood function.
Combining the prior and the likelihood results in the Gaussian Posterior, which we then can be used as a surface over which we try to optimize. \\

Bayesian optimization is a method that has increasingly gained attention in the last decades, as it requires relatively few points to find an appropriate response surface for the function over which we want to optimize over.
It is a sequential model based optimization function, which means that we choose the best point $x^*_i$ given all previous points $x^*_{i-1}, x^*_{i-2}, \ldots, x^*_{0}$.
Given certain acquisition functions, it offers a good mixture of exploration and exploitation from an empirical standpoint. \\

Bayesian optimization is a method that has increasingly gained success in finding a good mixture between exploration the search space (finding new hyper-parameter configurations that outperform all existing configurations), and exploiting currently found best configurations (using the best learned hyper-parameter configurations to get utility out of the system). \\

However, as machine learning algorithms and other problems become more complex, Bayesian optimization needs to cope with the increasing number of dimensions that define the search space of possible configurations.
Because BO methods loose effectiveness in higher dimensions, this work deals with methods that work in higher dimensions.

\section{Gaussian Processes}
In Bayesian Optimization, we want to use a Gaussian Process to find an optimal parameter setting $\mathbf{x^*}$ that maximizes a given utility function $f$.
We assume the response surface to be Lipschitz-continuous. \\

Assume we have observations $ \mathcal{Y} = \{ y^{(1)}, \ldots, y^{(N)} \}$, each evaluated at a point $ \mathcal{X} = \{  \mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(N)} \}$.
The relationship between the observations $y$ and individual parameter settings $\mathbf{x}$ is $y = f \left( \mathbf{x} \right) + \epsilon$ where $\epsilon \sim  \mathcal{N} \left( 0, \sigma^2_n \right)$. Any quantity to be predicted has a subscript-star (e.g. $y_*$ is the function evaluation we want to predict).\\

In it's simplest form, a Gaussian Process is described by the following equation:

\begin{equation}
\begin{pmatrix} y \\
y_* \end{pmatrix} \sim N\Biggl(\mu,\begin{pmatrix} K & K^T_*\\
 K_* & K_{**} \end{pmatrix}\Biggr),
\end{equation}

Where $\mu$ is a mean function, $K = \text{kernel}(\mathbf{X}, \mathbf{X})$, $K_* = \text{kernel}(\mathbf{x_*}, \mathbf{X})$ and $K_{**} = \text{kernel}(\mathbf{x_*}, \mathbf{x_*})$.
We predict any new point $y_*$, (given all previously sampled points $y$) by estimating the probability $ p(y_*|y) \sim N(K_*K^{-1}y,K_{**}-K_*K^{-1}K'_*) $

This, in turn, can be used to build an acquisition function. 
This acquisition function describes where to best sample points next.
Some popular acquisition functions include GP-UCB, Most probable improvement (MPI) and Expected Improvement (EI).
The choice of the acquisition function has significant influence on the performance of the optimization procedure.\\

We will talk about the problems and possible solutions for the task at hand in the next section.

\subsection{Derivation of the Gaussian Process Formula}
The prior for the Gaussian Process it the following (assuming a 0-mean-prior).

\begin{equation}
u \sim GP(0, k(x, x'))
\end{equation}

Because $u$ is a random variable, it's probably distribution is given by a normal distribution (as determined by the Gaussian Process):

\begin{equation}
p(u) = N ( 0, K )
\end{equation}

Now we go over to observing some data $ X = \{ (x_1, y_1), \ldots, (x_n, y_n) \} $ where $y$ has some noise term $\epsilon$ such that $y = u(x) + \epsilon$.
We assume that $\epsilon$ is normally distributed around $0$ with $\sigma$ standard deviation.
This means that the likelihood takes on the following form:

\begin{equation}
p(y | x, u) = N (u, \sigma^2 I)
\end{equation}

% https://stats.stackexchange.com/questions/84058/derivation-of-predictive-distribution-of-gaussian-process

Now we want to derive the posterior of the Gaussian Process, given the likelihood and the prior.
We use Bayes rule to derive this.

\begin{align}
p(u | x, y) &= \frac{ p(y | x, u) p(u) }{p(y | x)}
& = N( K(K +\sigma^2 I)^{-1}y, \sigma^2 (K + \sigma^2 I)^{-1} K )
\end{align}

At this point, we want to create a surrogate embedding, which predicts $y_*$ for any possible given $x_*$. 
We refer to this as the surrogate response surface.

We use the following formula to derive the posterior distribution for a given predictor $y_*$.

\begin{equation}
\begin{pmatrix} y \\
y_* \end{pmatrix} \sim N\Biggl(\mu,\begin{pmatrix} K & K^T_*\\
 K_* & K_{**} \end{pmatrix}\Biggr),
\end{equation}

To numerically calculate this, one uses the Matrix Inversion Lemma (CITE Murphy Chapter 4.3 110-111)


\section{Acquisition Functions}

Given the above formula for the posterior mean $\mu$ and the poster variance $\sigma^2$, Bayesian Optimization uses an acquisition function to optimize over.
We quickly present some of the most common acquisition functions.

% Most formulae taken from "A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning

\subsection{Upper Confident Bound (UCB)}
(CITE Krause Srinivas) about how acquisition function is guaranteed to find the best config after awhile.

The upper confidence bound allows the user to control exploitation and exploration through a parameter $\beta > 0$, which can be chosen as CITE PAPER, to offer optimality guarantees.

\begin{equation}
UCB(x) = \mu(x) + \beta \sigma(x)
\end{equation}

Here, the functions $\mu$ and $\sigma$ are the predicted mean and variance of the Gaussian Process Posterior.

\subsection{Probability of Improvement (PI)}
The (maximum) probability of improvement always selects the point which has the highest potential to maximize the function. 
The downside to this policy is that this leads to exploitation, which can be controlled by a parameter $\xi > 0$.

\begin{align}
    PI(x) & = P( f(x) \geq f(x^+) + \xi ) \\
    & = \Phi ( \frac{\mu(x) - f(x^+) - \xi}{\sigma(x)}  ) 
\end{align}


\subsection{Expected Improvement (EI)}

"CITE A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning."
\begin{align}
    EI(x) =
    \begin{dcases}
        ( \mu (x) - f(x^+) \Phi(Z) \sigma (x) \phi (Z) ) & \text{ if } \sigma (x) > 0 \\
        0 & \text{ if } \sigma (x) = 0
    \end{dcases} \\
\end{align}

\begin{equation}
    Z = \frac{\mu (x) - f(x^+) }{\sigma(x)}
\end{equation}

Given one of the above acquisition functions, we then use an optimizer such as $L-BFGS$, to find an approximate global maximum of the respective function.
The combination of Gaussian Processes and Acquisition function together result in a Bayesian Optimization algorithm, which has a prior assumption about the function to be learned and uses data samples to create a likelihood to refine the posterior of the function assumption further.

\section{Resources}
(CITE https://github.com/SheffieldML/GPy)
We will use "GPy: A Gaussian process framework in python" and "CITE https://github.com/SheffieldML/GPyOpt" by the Sheffield Machine Learning Group.
In addition to that, the febo framework developed by Johannes Kirschner from the Learning and Adaptive Systems group at ETH Zurich.
We use pytest to write tests (CITE).

% BFGS: https://stats.stackexchange.com/questions/284712/how-does-the-l-bfgs-work